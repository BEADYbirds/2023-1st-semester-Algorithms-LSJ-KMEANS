{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a378b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "#방법6 dbscan을 이용해서 초기 클러스터링 중심을 선정하는 방법\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "import time\n",
    "\n",
    "\n",
    "class Task(): \n",
    "\n",
    "    # add one ground with initiation\n",
    "    def __init__(self, task_id, x, y, area): \n",
    "        self.x_array = np.empty(shape = (0), dtype = 'float64')\n",
    "        self.y_array = np.empty(shape = (0), dtype = 'float64')\n",
    "        self.area_array = np.empty(shape = (0), dtype = 'float64')\n",
    "\n",
    "        self.taskid = task_id\n",
    "        self.ground_count = 0\n",
    "        self.ground_total_area = 0\n",
    "        self.add_ground(x, y, area)\n",
    "\n",
    "    # add Ground component\n",
    "    def add_ground(self, x, y, area): \n",
    "        self.x_array = np.append(self.x_array, x)\n",
    "        self.y_array = np.append(self.y_array, y)\n",
    "        self.area_array = np.append(self.area_array, area)\n",
    "        \n",
    "        self.ground_count += 1\n",
    "        self.ground_total_area += area\n",
    "\n",
    "    def get_taskid(self):\n",
    "        return self.taskid\n",
    "\n",
    "    def get_ground_count(self):\n",
    "        return self.ground_count\n",
    "\n",
    "    def get_ground_total_area(self):\n",
    "        return self.ground_total_area\n",
    "\n",
    "    \n",
    "    def print(self):\n",
    "        print('TaskID:', self.taskid)\n",
    "        #for i in range(0, self.ground_count):\n",
    "        #    print('x: ', self.x_array[i], ' / y: ', self.y_array[i], ' / area: ', self.area_array[i])\n",
    "        print('This Task has', self.ground_count, 'grounds.')\n",
    "        print('Total area of this Task is:', self.ground_total_area, 'm^2')\n",
    "        print('End of data.\\n\\n')\n",
    "\n",
    "\n",
    "class DBSCANCluster:\n",
    "    UNCLASSIFIED = False\n",
    "    NOISE = -1 \n",
    "    def __init__(self, m, eps, min_points):\n",
    "        self.m = m\n",
    "        self.eps = eps\n",
    "        self.min_points = min_points\n",
    "        # Change self.m.shape[1] to self.m.shape[0] to match the number of samples in the dataset\n",
    "        self.classifications = [self.UNCLASSIFIED] * self.m.shape[0]\n",
    "        self.classifications_list = {}\n",
    "\n",
    "    def _dist(self, p, q):\n",
    "        return math.sqrt(np.power(p - q, 2).sum())\n",
    "\n",
    "    def _eps_neighborhood(self, p, q, eps):\n",
    "        return self._dist(p, q) < eps\n",
    "    \n",
    "    def _expand_cluster(self, point_id, cluster_id):\n",
    "        seeds = self._region_query(point_id)\n",
    "        if len(seeds) < self.min_points:\n",
    "            self.classifications[point_id] = self.NOISE  # classify as noise\n",
    "            return False\n",
    "        else:\n",
    "            self.classifications[point_id] = cluster_id\n",
    "            self.classifications_list[cluster_id] = seeds\n",
    "            return True\n",
    "\n",
    "    def _region_query(self, point_id):\n",
    "        n_points = self.m.shape[0]  # Change self.m.shape[1] to self.m.shape[0] to match the number of samples in the dataset\n",
    "        seeds = []\n",
    "        for i in range(0, n_points):\n",
    "            if self._eps_neighborhood(self.m[point_id, :], self.m[i, :], self.eps):  # use self.m[point_id, :] and self.m[i, :] to represent points\n",
    "                seeds.append(i)\n",
    "        return seeds\n",
    "\n",
    "    def _expand_cluster(self, point_id, cluster_id):\n",
    "        seeds = self._region_query(point_id)\n",
    "        if len(seeds) < self.min_points:\n",
    "            self.classifications[point_id] = self.NOISE\n",
    "            return False\n",
    "        else:\n",
    "            self.classifications[point_id] = cluster_id\n",
    "            self.classifications_list[cluster_id] = seeds\n",
    "            return True\n",
    "\n",
    "    def apply(self):\n",
    "        cluster_id = 1\n",
    "        for point_id in range(0, self.m.shape[0]):  # Change self.m.shape[1] to self.m.shape[0] to match the number of samples in the dataset\n",
    "            if self.classifications[point_id] == self.UNCLASSIFIED:\n",
    "                if self._expand_cluster(point_id, cluster_id):\n",
    "                    cluster_id += 1\n",
    "        return self.classifications\n",
    "\n",
    "    def get_core_samples_indices(self):\n",
    "        core_samples_indices = []\n",
    "        for cluster_id, points in self.classifications_list.items():\n",
    "            core_samples_indices.extend(points)\n",
    "        return core_samples_indices\n",
    "\n",
    "    def get_labels(self):\n",
    "        return self.classifications\n",
    "\n",
    "\n",
    "class K_means():\n",
    "    def __init__(self, Task, cycle = 10, eps=0.00006, min_points=5):\n",
    "        self.cycle = cycle\n",
    "        self.variation = -1.0\n",
    "        self.eps = eps  # Added this line\n",
    "        self.min_points = min_points \n",
    "        self.k = 3\n",
    "        self.data_size = Task.ground_count\n",
    "        self.data_array = np.zeros(shape = (self.data_size, 4), dtype = 'float64')\n",
    "        self.minimum_area = 33057.8512\n",
    "        self.error_count = 0\n",
    "\n",
    "        self.data_array[:, 0] = Task.x_array.copy()\n",
    "        self.data_array[:, 1] = Task.y_array.copy()\n",
    "        self.data_array[:, 2] = Task.area_array.copy()\n",
    "\n",
    "        #self.old_centers = np.empty(shape = (self.k, 2), dtype = 'float64')\n",
    "        self.old_total_area = np.empty(shape = (0), dtype = 'float64')\n",
    "\n",
    "    def set_centers_from_dbscan(self):\n",
    "        data = self.data_array[:, :2]\n",
    "        dbscan = DBSCANCluster(data, eps=self.eps, min_points=self.min_points)\n",
    "        self.groups = dbscan.apply()  # Set self.groups\n",
    "        core_samples_mask = np.zeros_like(self.groups, dtype=bool)\n",
    "        core_samples_mask[dbscan.get_core_samples_indices()] = True\n",
    "        unique_labels = set(self.groups)\n",
    "        self.centers = []\n",
    "        for k in unique_labels:\n",
    "            if k == DBSCANCluster.NOISE:  # skip the noise cluster\n",
    "                continue\n",
    "            class_member_mask = (self.groups == k)\n",
    "            xy = self.data_array[class_member_mask & core_samples_mask, :2]\n",
    "            if len(xy) > 0:\n",
    "                center = xy.mean(axis=0)\n",
    "                self.centers.append(center)\n",
    "            else:\n",
    "                print(f\"클러스터가 아닌 점: {k}. Skipping...\")\n",
    "\n",
    "\n",
    "\n",
    "    def clustering(self):\n",
    "        for i in range(0, self.data_size):\n",
    "            min_dist = float('inf')\n",
    "            nearest_center = -1\n",
    "\n",
    "            x = self.data_array[i][0]\n",
    "            y = self.data_array[i][1]\n",
    "\n",
    "        for j in range(len(self.centers)): # ensure j is within the range of self.centers\n",
    "            tx = self.centers[j][0]\n",
    "            ty = self.centers[j][1]\n",
    "\n",
    "            distance = ((tx - x) * (tx - x)) + ((ty - y) * (ty - y))\n",
    "            if min_dist > distance:\n",
    "                min_dist = distance\n",
    "                nearest_center = j\n",
    "\n",
    "        if nearest_center != -1: # this check will make sure that we are assigning a valid center\n",
    "            self.data_array[i][3] = nearest_center\n",
    "\n",
    "\n",
    "    def center_adjusting(self):\n",
    "        temp_array = np.zeros(shape = (self.k, 3), dtype = 'float64')\n",
    "\n",
    "        #sum all of x and y value and count\n",
    "        for i in range(0, self.data_size):\n",
    "            temp = int(self.data_array[i][3])\n",
    "\n",
    "            temp_array[temp][0] += self.data_array[i][0]\n",
    "            temp_array[temp][1] += self.data_array[i][1]\n",
    "            temp_array[temp][2] += 1\n",
    "\n",
    "        # devide all of x and y to count\n",
    "        for i in range(0, self.k):\n",
    "            #if one of groups has 0 count of ground.\n",
    "            #means, that group has disappeared.\n",
    "            count = temp_array[i][2]\n",
    "            if not count:\n",
    "                return -1  #error code\n",
    "            temp_array[i][0] /= count\n",
    "            temp_array[i][1] /= count\n",
    "\n",
    "        flag = False\n",
    "        for i in range(0, self.k): # compare that center has moved\n",
    "            if temp_array[i][0] != self.centers[i][0]:\n",
    "                flag = True\n",
    "                break\n",
    "            if temp_array[i][1] != self.centers[i][1]:\n",
    "                flag = True\n",
    "                break\n",
    "\n",
    "        if flag: #if it moved\n",
    "            for i in range(0, self.k):\n",
    "                self.centers[i][0] = temp_array[i][0]\n",
    "                self.centers[i][1] = temp_array[i][1]\n",
    "            return 1\n",
    "\n",
    "        else: #else\n",
    "            return 0\n",
    "\n",
    "    def adjust_total_area(self):\n",
    "        #sum all total_area of each groups.\n",
    "        self.total_area = np.zeros(shape = (self.k), dtype = 'float64')   \n",
    "        for i in range(0, self.data_size):\n",
    "            self.total_area[int(self.data_array[i][3])] += self.data_array[i][2]\n",
    "\n",
    "        # make 2di_array of distance between all dots and centers.\n",
    "        distance_array = np.empty(shape = (self.k, self.data_size), dtype = 'float64')\n",
    "        for i in range(0, self.k):\n",
    "            tx = self.centers[i][0]\n",
    "            ty = self.centers[i][1]\n",
    "            for j in range(0, self.data_size):\n",
    "                x = self.data_array[j][0]\n",
    "                y = self.data_array[j][1]\n",
    "                                \n",
    "                distance_array[i][j] = ((tx - x) * (tx - x)) + ((ty - y) * (ty - y))\n",
    "\n",
    "        # READ (README FILE/class K_means) to get more info.\n",
    "        marker_array = np.zeros(shape = (self.data_size), dtype = int)\n",
    "\n",
    "        flag = True\n",
    "        while flag:\n",
    "            temp_array = self.total_area.copy()\n",
    "            for i in range(0, self.k):\n",
    "                if self.total_area[i] < self.minimum_area:\n",
    "                    record1 = -1\n",
    "                    record2 = -1\n",
    "                    while self.total_area[i] < self.minimum_area:\n",
    "                        temp1 = -1.0\n",
    "                        for j in range(0, self.data_size):\n",
    "                            if int(self.data_array[j][3]) != i:\n",
    "                                if not marker_array[j]:\n",
    "                                    temp2 = distance_array[i][j]\n",
    "                                    if temp1 == -1.0 or temp1 > temp2:\n",
    "                                        temp1 = temp2\n",
    "                                        record1 = j\n",
    "                            else:\n",
    "                                marker_array[j] = 1\n",
    "                                \n",
    "                        record2 = int(self.data_array[record1][3])\n",
    "                        self.data_array[record1][3] = i\n",
    "                        self.total_area[i] += self.data_array[record1][2]\n",
    "                        self.total_area[record2] -= self.data_array[record1][2]\n",
    "\n",
    "                        marker_array[record1] = 1\n",
    "                        \n",
    "                    self.data_array[record1][3] = record2\n",
    "                    self.total_area[i] -= self.data_array[record1][2]\n",
    "                    self.total_area[record2] += self.data_array[record1][2]\n",
    "\n",
    "                    marker_array[record1] = 0\n",
    "\n",
    "            for i in range(0, self.k):\n",
    "                if temp_array[i] != self.total_area[i]:\n",
    "                    flag = True\n",
    "                    break\n",
    "                \n",
    "                else:\n",
    "                    flag = False\n",
    "\n",
    "    def calculate_variation(self, field = False):\n",
    "        all_sum = 0.0\n",
    "        for i in range(0, self.data_size):\n",
    "            temp = int(self.groups[i]) - 1 # self.groups is more meaningful and adjust index for zero-based array\n",
    "\n",
    "            if temp >= 0 and temp < len(self.centers): # check if temp is within valid range\n",
    "                x = self.data_array[i][0]\n",
    "                y = self.data_array[i][1]\n",
    "                tx = self.centers[temp][0]\n",
    "                ty = self.centers[temp][1]\n",
    "\n",
    "                all_sum += ((tx - x) * (tx - x)) + ((ty - y) * (ty - y))\n",
    "\n",
    "        #if variation had changed, return 1\n",
    "        if (self.variation == -1.0) or (self.variation > all_sum):\n",
    "            self.variation = all_sum\n",
    "\n",
    "            if field:\n",
    "                self.old_total_area = self.total_area.copy()\n",
    "            return 1\n",
    "\n",
    "        #else, return 0\n",
    "        return 0\n",
    "\n",
    "    # calculate variation of \"real devided  info.\"\n",
    "    def get_default_variation(self):\n",
    "        self.variation = -1.0\n",
    "        self.set_centers_from_dbscan()\n",
    "        self.center_adjusting()\n",
    "        self.calculate_variation()\n",
    "        return self.variation\n",
    "\n",
    "    #normal k_means\n",
    "    def random_kmeans(self):\n",
    "        i = 0\n",
    "        count = 0\n",
    "        self.variation = -1.0\n",
    "        while i < self.cycle:\n",
    "            if self.error_count >= 100:\n",
    "                print(\"error return\")\n",
    "                return\n",
    "            #print(i)\n",
    "            self.set_centers_from_dbscan()\n",
    "            self.clustering()\n",
    "\n",
    "            flag = 1\n",
    "            while flag == 1: # while centers dont move anymore\n",
    "                flag = self.center_adjusting()\n",
    "                self.clustering()\n",
    "\n",
    "            # if one of group didnt disappear.\n",
    "            if flag != -1:\n",
    "                # if variation change has occured.\n",
    "                if self.calculate_variation():\n",
    "                    i = 0\n",
    "                #else\n",
    "                else:\n",
    "                    i += 1\n",
    "            else:\n",
    "                self.error_count += 1\n",
    "\n",
    "        self.error_count = 0\n",
    "        print('Variation:', self.variation, '\\nthis time cycle number is:', count)\n",
    "\n",
    "    # special kmeans with \"considering area need.\"\n",
    "    def special_kmeans(self):\n",
    "        i = 0\n",
    "        count = 0\n",
    "        self.variation = -1.0\n",
    "        while i < self.cycle:\n",
    "            if self.error_count >= 100:\n",
    "                print(\"error return\")\n",
    "                return\n",
    "            #print(i)\n",
    "            count += 1\n",
    "            self.set_centers_from_dbscan()\n",
    "            self.clustering()\n",
    "\n",
    "            flag = 1\n",
    "            while flag == 1: # while centers dont move anymore\n",
    "                flag = self.center_adjusting()\n",
    "                self.clustering()\n",
    "\n",
    "            # if one of group didnt disappear. and there are more than 1group.\n",
    "            if flag != -1 and self.k > 1:\n",
    "                self.adjust_total_area()\n",
    "                self.center_adjusting()\n",
    "                # if variation change has occured.\n",
    "                if self.calculate_variation(True):\n",
    "                    i = 0\n",
    "                #else\n",
    "                else:\n",
    "                    i += 1\n",
    "\n",
    "        self.error_count = 0\n",
    "        print('Group total area\\n', self.old_total_area)\n",
    "        print('\\nVariation:', self.variation, '\\nthis time cycle number is:', count)\n",
    "\n",
    "    def get_x_array(self):\n",
    "        return self.data_array[:, 0]\n",
    "    \n",
    "    def get_y_array(self):\n",
    "        return self.data_array[:, 1]\n",
    "    \n",
    "    def get_group_array(self):\n",
    "        return self.data_array[:, 3]\n",
    "    \n",
    "    def get_group_min_max_xy(self):\n",
    "        # self.k rows\n",
    "        # 4 columns (minX, minY, maxX, maxY)\n",
    "        temp_array = np.zeros(shape = (self.k, 4), dtype = 'float64')\n",
    "        for i in range(0, self.data_size):\n",
    "            group_num = int(self.data_array[i, 3])\n",
    "            if temp_array[group_num, 0] == 0:\n",
    "                temp_array[group_num, 0] = self.data_array[i, 0]\n",
    "                temp_array[group_num, 1] = self.data_array[i, 1]\n",
    "                temp_array[group_num, 2] = self.data_array[i, 0]\n",
    "                temp_array[group_num, 3] = self.data_array[i, 1]\n",
    "                continue\n",
    "            if temp_array[group_num, 0] > self.data_array[i, 0]:\n",
    "                temp_array[group_num, 0] = self.data_array[i, 0]\n",
    "            if temp_array[group_num, 1] > self.data_array[i, 1]:\n",
    "                temp_array[group_num, 1] = self.data_array[i, 1]\n",
    "            if temp_array[group_num, 2] < self.data_array[i, 0]:\n",
    "                temp_array[group_num, 2] = self.data_array[i, 0]\n",
    "            if temp_array[group_num, 3] < self.data_array[i, 1]:\n",
    "                temp_array[group_num, 3] = self.data_array[i, 1]\n",
    "                \n",
    "        return temp_array\n",
    "\n",
    "\n",
    "\n",
    "def read_csv(file_name):\n",
    "    return_list = []\n",
    "    \n",
    "    f = open(file_name, 'r', encoding = 'utf-8')\n",
    "\n",
    "    i = 0\n",
    "    for row in csv.reader(f):\n",
    "        if i == 0:\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        flag = False\n",
    "        taskid = 0\n",
    "        x = float(row[0])\n",
    "        y = float(row[1])\n",
    "        area = float(row[2])\n",
    "        if x <= 129 and x >= 128 and y <= 37 and y >= 36:\n",
    "            for task in return_list:\n",
    "                if task.get_taskid() == taskid:\n",
    "                    task.add_ground(x, y, area)\n",
    "                    flag = True\n",
    "                    break\n",
    "            if not flag:\n",
    "                return_list.append(Task(taskid, x, y, area))\n",
    "            \n",
    "        #if i == 1000:\n",
    "        #    break\n",
    "        i += 1\n",
    "        \n",
    "    print('Task set finished\\n')\n",
    "\n",
    "    return return_list\n",
    "\n",
    "\n",
    "\n",
    "task_list = []\n",
    "\n",
    "task_list = read_csv('./sorted_data.csv')\n",
    "\n",
    "f = open('result_sum.csv','a', newline='')\n",
    "wr = csv.writer(f)\n",
    "\n",
    "for task in task_list:\n",
    "    kmeans = K_means(task)\n",
    "\n",
    "    task.print()\n",
    "    \n",
    "    dv = kmeans.get_default_variation()\n",
    "    print('This is default variation', dv)\n",
    "    \n",
    "    df = pd.DataFrame({'x': kmeans.get_x_array(),\n",
    "                        'y': kmeans.get_y_array(),\n",
    "                        'color': kmeans.get_group_array()})\n",
    "    sns.lmplot(x = 'x', y = 'y',\n",
    "               hue = 'color', data = df,\n",
    "               fit_reg = False,\n",
    "               scatter_kws = {\"s\": 10})\n",
    "    \n",
    "    print('\\nRANDOM K_MEANS')\n",
    "    start = time.time()\n",
    "    kmeans.random_kmeans()\n",
    "    time1 = time.time() - start\n",
    "    print('it took', round(time1, 3), 'secs.')\n",
    "    print(kmeans.get_group_min_max_xy())\n",
    "    df = pd.DataFrame({'x': kmeans.get_x_array(),\n",
    "                       'y': kmeans.get_y_array(),\n",
    "                        'color': kmeans.get_group_array()})\n",
    "    sns.lmplot(x = 'x', y = 'y',\n",
    "               hue = 'color', data = df,\n",
    "               fit_reg = False,\n",
    "               scatter_kws = {\"s\": 10})\n",
    "\n",
    "    print('\\nSPECIAL K_MEANS')\n",
    "    start = time.time()\n",
    "    kmeans.special_kmeans()\n",
    "    time2 = time.time() - start\n",
    "    print('it took', round(time2, 3), 'secs.')\n",
    "    print(kmeans.get_group_min_max_xy())\n",
    "    df = pd.DataFrame({'x': kmeans.get_x_array(),\n",
    "                       'y': kmeans.get_y_array(),\n",
    "                        'color': kmeans.get_group_array()})\n",
    "    sns.lmplot(x = 'x', y = 'y',\n",
    "               hue = 'color', data = df,\n",
    "               fit_reg = False,\n",
    "                scatter_kws = {\"s\": 10})\n",
    "\n",
    "    plt.show(block = True)\n",
    "\n",
    "    print('========================================')\n",
    "\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "print(\"2018125042 이석준\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
